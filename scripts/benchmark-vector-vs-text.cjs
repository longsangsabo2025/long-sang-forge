/**
 * Benchmark: TEXT vs VECTOR parameter for pgvector search
 * ========================================================
 * So s√°nh performance gi·ªØa 2 c√°ch truy·ªÅn embedding v√†o function
 */

require("dotenv").config();
const { Client } = require("pg");
const { createClient } = require("@supabase/supabase-js");
const OpenAI = require("openai");

const SUPABASE_URL = process.env.VITE_SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const OPENAI_KEY = process.env.OPENAI_API_KEY;

const c = new Client({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false },
});

async function benchmark() {
  await c.connect();
  const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);
  const openai = new OpenAI({ apiKey: OPENAI_KEY });

  console.log("=".repeat(60));
  console.log("BENCHMARK: TEXT vs VECTOR parameter for pgvector");
  console.log("=".repeat(60));

  // Generate test embedding
  const query = "Long Sang cung cap dich vu thiet ke website";
  console.log("\nQuery:", query);

  const embRes = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: query,
  });
  const embedding = embRes.data[0]?.embedding;
  const embeddingText = `[${embedding.join(",")}]`;

  console.log("Embedding dims:", embedding.length);
  console.log("Text format size:", embeddingText.length, "bytes");

  const ITERATIONS = 10;

  // ============================================
  // TEST 1: Direct SQL with VECTOR (Gold standard)
  // ============================================
  console.log("\n" + "-".repeat(60));
  console.log("TEST 1: Direct SQL with native VECTOR type");
  console.log("-".repeat(60));

  let times1 = [];
  for (let i = 0; i < ITERATIONS; i++) {
    const start = performance.now();
    await c.query(
      `
      SELECT title, (1 - (embedding <=> $1::vector))::float as similarity
      FROM brain_knowledge
      WHERE embedding IS NOT NULL
        AND 1 - (embedding <=> $1::vector) > 0.25
      ORDER BY embedding <=> $1::vector
      LIMIT 3
    `,
      [embeddingText]
    );
    times1.push(performance.now() - start);
  }
  console.log(`Avg: ${(times1.reduce((a, b) => a + b) / ITERATIONS).toFixed(2)}ms`);
  console.log(`Min: ${Math.min(...times1).toFixed(2)}ms, Max: ${Math.max(...times1).toFixed(2)}ms`);

  // ============================================
  // TEST 2: brain_search function (TEXT param)
  // ============================================
  console.log("\n" + "-".repeat(60));
  console.log("TEST 2: brain_search function (TEXT parameter)");
  console.log("-".repeat(60));

  let times2 = [];
  for (let i = 0; i < ITERATIONS; i++) {
    const start = performance.now();
    await c.query(`SELECT * FROM brain_search($1, 0.25, 3)`, [embeddingText]);
    times2.push(performance.now() - start);
  }
  console.log(`Avg: ${(times2.reduce((a, b) => a + b) / ITERATIONS).toFixed(2)}ms`);
  console.log(`Min: ${Math.min(...times2).toFixed(2)}ms, Max: ${Math.max(...times2).toFixed(2)}ms`);

  // ============================================
  // TEST 3: REST API with brain_search (TEXT)
  // ============================================
  console.log("\n" + "-".repeat(60));
  console.log("TEST 3: REST API via Supabase SDK (TEXT param)");
  console.log("-".repeat(60));

  let times3 = [];
  for (let i = 0; i < ITERATIONS; i++) {
    const start = performance.now();
    await supabase.rpc("brain_search", {
      embedding_text: embeddingText,
      threshold: 0.25,
      max_results: 3,
    });
    times3.push(performance.now() - start);
  }
  console.log(`Avg: ${(times3.reduce((a, b) => a + b) / ITERATIONS).toFixed(2)}ms`);
  console.log(`Min: ${Math.min(...times3).toFixed(2)}ms, Max: ${Math.max(...times3).toFixed(2)}ms`);

  // ============================================
  // TEST 4: REST API with match_knowledge (VECTOR) - if works
  // ============================================
  console.log("\n" + "-".repeat(60));
  console.log("TEST 4: REST API with VECTOR param (match_knowledge)");
  console.log("-".repeat(60));

  let times4 = [];
  let vectorApiWorks = true;
  for (let i = 0; i < ITERATIONS; i++) {
    const start = performance.now();
    const result = await supabase.rpc("match_knowledge", {
      query_embedding: embeddingText,
      match_threshold: 0.25,
      match_count: 3,
    });
    times4.push(performance.now() - start);
    if (result.error && i === 0) {
      console.log("‚ùå VECTOR API Error:", result.error.message);
      vectorApiWorks = false;
      break;
    }
  }
  if (vectorApiWorks) {
    console.log(`Avg: ${(times4.reduce((a, b) => a + b) / ITERATIONS).toFixed(2)}ms`);
    console.log(
      `Min: ${Math.min(...times4).toFixed(2)}ms, Max: ${Math.max(...times4).toFixed(2)}ms`
    );
  }

  // ============================================
  // SUMMARY
  // ============================================
  console.log("\n" + "=".repeat(60));
  console.log("SUMMARY");
  console.log("=".repeat(60));

  const avg1 = times1.reduce((a, b) => a + b) / ITERATIONS;
  const avg2 = times2.reduce((a, b) => a + b) / ITERATIONS;
  const avg3 = times3.reduce((a, b) => a + b) / ITERATIONS;

  console.log(`
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Method                              ‚îÇ Avg (ms) ‚îÇ Status  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Direct SQL (VECTOR)                 ‚îÇ ${avg1.toFixed(2).padStart(8)} ‚îÇ ‚úÖ Best ‚îÇ
‚îÇ brain_search func (TEXT via pg)    ‚îÇ ${avg2.toFixed(2).padStart(8)} ‚îÇ ‚úÖ Good ‚îÇ
‚îÇ REST API brain_search (TEXT)        ‚îÇ ${avg3.toFixed(2).padStart(8)} ‚îÇ ‚úÖ Works‚îÇ
‚îÇ REST API match_knowledge (VECTOR)   ‚îÇ ${
    vectorApiWorks
      ? (times4.reduce((a, b) => a + b) / ITERATIONS).toFixed(2).padStart(8)
      : "   N/A  "
  } ‚îÇ ${vectorApiWorks ? "‚úÖ Works" : "‚ùå Cache"} ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìä ANALYSIS:
- Direct SQL lu√¥n nhanh nh·∫•t (kh√¥ng qua HTTP)
- TEXT vs VECTOR trong function: ~same performance (cast ch·ªâ 0.01ms)
- REST API overhead: ~${(avg3 - avg2).toFixed(0)}ms (network latency)
- VECTOR via REST: ${vectorApiWorks ? "Works!" : "BLOCKED by PostgREST schema cache"}

üéØ CONCLUSION:
${
  vectorApiWorks
    ? "‚úÖ C·∫£ hai ƒë·ªÅu ho·∫°t ƒë·ªông, VECTOR h∆°i nhanh h∆°n do kh√¥ng c·∫ßn cast"
    : `‚ùå VECTOR param b·ªã block b·ªüi PostgREST cache issue
   ‚Üí TEXT param l√† workaround duy nh·∫•t ho·∫°t ƒë·ªông qua REST API
   ‚Üí Performance impact: ~0.01ms (kh√¥ng ƒë√°ng k·ªÉ)`
}
`);

  await c.end();
}

benchmark().catch((e) => console.error("Error:", e.message));
